---
title: "Power analysis Helmut's Nature Ecol Evol paper"
author: "Yefeng"
date: "2020/9/21"
output: html_document
subtitle: "check for Shinichi"
---


## Setup

```{r setup, echo = FALSE}
# Tidy
 # rm(list=ls())
 # graphics.off()

# Preparing workspace
knitr::opts_chunk$set(echo = TRUE, include = TRUE)

# Loading packages
pacman::p_load(knitr, # knit markdown
               readxl, 
               readr, 
               metafor, 
               dplyr, 
               tidyverse, 
               janitor, # generate 1-, 2-way table
               patchwork, # layout of plots
               cowplot, 
               ggpubr,
               gridExtra,
               orchaRd, # forest-like plot
               gridGraphics # Redraw Base Graphics Using 'grid' Graphics. `gridGraphics` is required to handle base-R plots.
               )
```



**Contents**
We have three sections. 

Section 1: power analysis for 36 lnRR meta-analyses and corresponding  power analysis for individual data point within each meta-analysis

Section 2: power analysis for 12 lnCVR and lnVR meta-analyses and corresponding  power analysis for individual data point within each meta-analysis

Section3: using three three weighting schemes (i.e. WAAP, PET-PEESE, http://environmentalcomputing.net/meta-analysis/) to evaluate publication



### Section 1 & 2 - power analysis for lnRR (Section 1), lnCVR and lnVR (Section 2)

Using multi-level meta-analysis estimate as true effect, we want to calculate two-tailed power for (i) 36 lnRR meta-analytic cases and individual empirical study within each meta-analysis; (ii) 12 lnCVR and lnVR meta-analytic cases 

In addition, we also want to calculate power using three hypothetical true effects (i.e. 5%, 10%, 20% mean differences)

For a pilot, I did Section 1 & 2 simutanelously, and did 1 case for check

```{r}
#***************************************************************#
#             power for 36 meta-analytic cases                  #
#***************************************************************#

# Importing raw data
raw_m1_1 <- read.csv(file = "./dataset/raw_m1_1.csv", header = TRUE) #sep=";"
# view(raw_m1_1)
raw_data <- raw_m1_1

# Renaming the column names
  names(raw_data)[str_detect(names(raw_data), c("T.mean|T.sd|T.N|C.mean|C.sd|C.N"))] <- c("T_mean", "T_sd", "T_N", "C_mean", "C_sd", "C_N")


    
# Calculating 3 type of effect size statistics
  
## lnRR
  lnRR <- with(raw_data, escalc(measure = "ROM",
                                m1i = T_mean,
                                m2i = C_mean,
                                sd1i = T_sd,
                                sd2i = C_sd,
                                n1i = T_N,
                                n2i = C_N))

## lnCVR
  lnCVR <- with(raw_data, escalc(measure = "CVR",
                                 m1i = T_mean,
                                 m2i = C_mean,
                                 sd1i = T_sd,
                                 sd2i = C_sd,
                                 n1i = T_N,
                                 n2i = C_N))
## lnVR
  lnVR <- with(raw_data, escalc(measure = "VR",
                                sd1i = T_sd,
                                sd2i = C_sd,
                                n1i = T_N,
                                n2i = C_N))


## combination 
  metrics <- data.frame(RR = lnRR$yi, VRR = lnRR$vi, CVR = lnCVR$yi, VCVR = lnCVR$vi, VR = lnVR$yi, VVR = lnVR$vi)
  dat_m1_1 <- cbind(raw_data, metrics)


# clean NA
  dat_m1_1 <- dat_m1_1[!is.na(dat_m1_1$RR),] 
  dat_m1_1 <- dat_m1_1[!is.na(dat_m1_1$VRR),] 
  dat_m1_1 <- dat_m1_1[!is.na(dat_m1_1$CVR),]
  dat_m1_1 <- dat_m1_1[!is.na(dat_m1_1$VCVR),]
  
  dat_m1_1[dat_m1_1 == "-Inf"] <- NA
  dat_m1_1[dat_m1_1 == "Inf"] <- NA  


# Fit multi-level meta-analytic model - prepare "ture" effect for power analysis
## RR
model_m1_1_RR <- with(dat_m1_1, rma.mv(yi = RR,
                                        V = VRR,
                                        random = list(~1|Study, ~1|Unit_ID),
                                        method = "REML",
                                        test = "z"))


## CVR
model_m1_1_CVR <- with(dat_m1_1, rma.mv(yi = CVR,
                                        V = VCVR,
                                        random = list(~1|Study, ~1|Unit_ID),
                                        method = "REML",
                                        test = "z"))


## VR
model_m1_1_VR <- with(dat_m1_1, rma.mv(yi = VR,
                                        V = VVR,
                                        random = list(~1|Study, ~1|Unit_ID),
                                        method = "REML",
                                        test = "z"))




# We want to use meta-analytic mean as ture effect, so we need to get estimate (mu) and corresponding error (SE)
model_m1_1 <- list(model_m1_1_RR,model_m1_1_CVR,model_m1_1_VR)

est_model_m1_1 <- data.frame(es.type=c("RR","CVR","VR"),
                  mu=sapply(model_m1_1, function(x) x$beta),
                  SE=sapply(model_m1_1, function(x) x$se),
                  p_value=sapply(model_m1_1, function(x) x$pval))



# Creat function to calculate power
power.ma_Shinichi <- function(mu, SE) {
  2-pnorm(qnorm(0.975)-abs(mu)/SE)-pnorm(qnorm(0.975)+abs(mu)/SE)
  } # two-tailed power

# Get two-tailed power
est_model_m1_1$MA.power <- power.ma_Shinichi(mu=est_model_m1_1$mu,SE=est_model_m1_1$SE)


# Save
write.csv(est_model_m1_1, file = "./meta-analysis power_m1_1.csv", row.names = FALSE)



#***************************************************************#
#       power for individual study within meta-analysis         #
#***************************************************************#

# Creating function for power analysis for empirical data point
power.individual_Shinichi <- function(mu, se) {
  2-pnorm(qnorm(0.975)-abs(mu)/se)-pnorm(qnorm(0.975)+abs(mu)/se)} # two-tailed power

# Using meta-analytic estimate as true effect size, to calculate power for individual data point
## RR
dat_m1_1$power_RR <-power.individual_Shinichi(mu=rep(est_model_m1_1$mu[1], length(dat_m1_1$VRR)), se=sqrt(dat_m1_1$VRR))

## CVR
dat_m1_1$power_CVR <-power.individual_Shinichi(mu=rep(est_model_m1_1$mu[1], length(dat_m1_1$VCVR)), se=sqrt(dat_m1_1$VCVR))

## VR
dat_m1_1$power_VR <-power.individual_Shinichi(mu=rep(est_model_m1_1$mu[1], length(dat_m1_1$VVR)), se=sqrt(dat_m1_1$VVR))


# Using 20% difference as true effect size, to calculate power for individual data point

## RR
dat_m1_1$d20_power_RR <-power.individual_Shinichi(mu=rep(log(120/100), length(dat_m1_1$VRR)), se=sqrt(dat_m1_1$VRR))

dat_m1_1$d20_power_CVR <-power.individual_Shinichi(mu=rep(log(120/100), length(dat_m1_1$VCVR)), se=sqrt(dat_m1_1$VCVR))

dat_m1_1$d20_power_VR <-power.individual_Shinichi(mu=rep(log(120/100), length(dat_m1_1$VVR)), se=sqrt(dat_m1_1$VVR))


# save
write.csv(dat_m1_1, file = "./individual_power_m1_1.csv", row.names = FALSE)

```



### Section 3 - three weighting schemes (i.e. WAAP, PET-PEESE, http://environmentalcomputing.net/meta-analysis/) to evaluate publication bias


```{r}
#***************************************************************#
#                          WAAP approach                        #
#***************************************************************#

# In our case, my understanding is we should call WAAP as random-effects-WAAP, because we do not want to use fixed effects model

# Selecting adequately powered studies
## We only use studies with power >80% or SE < 2.8
WAAP_dat_m1_1 <- dat_m1_1 %>% subset(power_RR > 0.8)

# Evaluating publication using adequately powered studies

WAAP_m1_1_RR <- with(WAAP_dat_m1_1, rma.mv(yi = RR,
                                         V = VRR,
                                         mods = ~sqrt(VRR),
                                         random = list(~1|Study, ~1|Unit_ID),
                                         method = "REML",
                                         test = "z"))

summary(WAAP_m1_1_RR)




#***************************************************************#
#                       PET-PEESE approach                      #
#***************************************************************#

# Get precision, i.e. 1/SE
dat_m1_1$SE <- sqrt(dat_m1_1$VRR) # note it is SE rather than variance (V), so we should use sqrt(V)

# PET model - specifing 1/se^2 as weights
PET.m1_1 <- lm(RR~SE, weights =(1/SE)**2,data=dat_m1_1) # This form (OLS) reverse the intercept and slope coefficient from WLS version. Therefore, intercept from WLS version is the slope from OLS version. So we should not remove intercept (i.e. -1)
summary(PET.m1_1) # intercept rather than slope is our expected estimate

# Or we can use two-step approach for PET
dat_m1_1$t <- dat_m1_1$RR/sqrt(dat_m1_1$VRR)
dat_m1_1$precision <- 1/sqrt(dat_m1_1$VRR)
# We got same results with the above
PET.m1_1_2 <- lm(t~precision, data=dat_m1_1)


# PET-PEESE model - same results with PET model
PET_PEESE.m1_1 <- lm(RR~SE**2, weights =(1/SE)**2,data=dat_m1_1)
summary(PET_PEESE.m1_1) # intercept rather than slope is our expected estimate





Note: I am not sure which approachs you want me to use to evaluate publication bias in this website: http://environmentalcomputing.net/meta-analysis/
  
Whatever, I used a regular model to evaluate publication, i.e. Egger regression test
#***************************************************************#
#                      Egger regression test                    #
#***************************************************************#

Egger_m1_1_RR <- with(dat_m1_1, rma.mv(yi = RR,
                                         V = VRR,
                                         mods = ~sqrt(VRR),
                                         random = list(~1|Study, ~1|Unit_ID),
                                         method = "REML",
                                         test = "z"))

summary(Egger_m1_1_RR) # Note that here we should look at slope, rather than intercept, which is a distinction from PET model

```

